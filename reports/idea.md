# 研究想法：TargetFormer-Crime

## 1. 研究背景与问题定义

UCF-Crime 是弱监督视频异常检测（Weakly-supervised Video Anomaly Detection, WS-VAD）的经典数据集：训练阶段仅提供**视频级标签**（Normal/Abnormal），而异常事件往往只发生在少量片段中且边界未知。该设定带来三个核心困难：

1) **稀疏正例问题**：异常片段占比小，基于全局特征的表示容易被大量正常背景“稀释”。  
2) **弱标签噪声问题**：视频级标签无法直接监督片段级定位，MIL 训练易出现“把背景当异常”的偏置。  
3) **可解释与可定位问题**：传统全局表示难以回答“异常由哪些目标/哪个片段触发”，不利于科研分析与工程落地。

## 2. 核心假设（Target-Centric）

真实监控场景中的异常行为往往与少数关键目标（targets）相关，例如：人与人/人与物交互、突然加速/跌倒/抢夺、车辆碰撞等。若将表示从“全帧全局”转为“**目标中心**”，并显式建模跨片段与跨目标的关系，可在弱监督学习中提升：

- 异常线索的信噪比（减少背景干扰）  
- 可解释性（定位到目标、轨迹与片段）  
- MIL 可学习性（从少数关键实例中挖掘模式）

## 3. 方法概述（端到端工程化流水线）

提出 **TargetFormer-Crime** 研究管线：

1) **检测与跟踪（YOLO + Tracking）**  
在稀疏采样帧上运行轻量级 YOLO（默认 person 类），并用稳定的跨帧关联策略获得轨迹级时序一致性（在 Windows 环境下避免不稳定的外部追踪器依赖）。

2) **目标中心 Token 化**  
将每个视频划分为固定 N 段（默认 32），每段选择 Top-K 轨迹实例（默认 10），为每个目标构造 token：  
几何（bbox 归一化）、运动（速度/加速度统计）、外观（ROI-CNN embedding），并投影到统一维度。

3) **TargetFormer（Transformer Encoder）**  
对 $(\text{segment}, \text{target})$ 二维 token 序列加入双位置编码（片段索引 + 目标索引），用 Transformer 学习跨片段与跨目标依赖，输出片段级异常分数 $s_i\in[0,1]$。

4) **弱监督 MIL 学习**  
每个视频为 bag，每段为 instance；采用 ranking-based MIL 损失约束异常视频的 max score 高于正常视频的 max score，并加入：  
平滑正则（相邻片段分数变化）与稀疏正则（鼓励异常视频只在少量片段出现峰值）。

5) **行为模式挖掘与可解释（Prototype Bank）**  
引入原型库对片段嵌入进行软分配，提供“模式原型—片段”对应关系，支持消融并可生成注意力/贡献热力图，用于解释异常依据与分析模式聚类结构。

## 4. 预期贡献

- 完整可复现的端到端研究流水线：审计 → 预处理 → 训练 → 评估 → 可视化 → 论文  
- 目标中心 token + Transformer 结构在 WS-VAD 的定位与解释方向的系统化探索  
- 覆盖基线（B1–B3）、消融（A1–A6）与 3 随机种子的统计结果与可视化证据链
