# 结果分析与讨论（基于 outputs/exp_20251230_073809）

## 1) 总体现象

从 `outputs/exp_20251230_073809/results_summary.json` 可观察到：

- 主模型 main_targetformer（3 seeds）在 video-level 上达到 AUC=0.8205 ± 0.0056，AP=0.7799 ± 0.0143。
- 令人意外的是，B1_global_mlp（无 YOLO/无 tracking，仅全帧特征）在本次设置下表现更高（AUC=0.8776，AP=0.8562）。
- B2_yolo_gru（目标 token + RNN）优于主模型（AUC=0.8472），B3_yolo_no_track（无 tracking）低于主模型（AUC=0.8079）。

该结果提示：在当前数据形态（已解帧、64×64、估算来源 fps 约为 3）的条件下，“全局场景线索”可能仍然是强判别因素，而目标中心管线的噪声（检测与关联误差）可能抵消了一部分结构优势。

## 2) 基线对比解读

### B1_global_mlp 为什么可能更强？

可能原因包括：

1) **分辨率与采样率导致目标信息弱化**：64×64 + 稀疏帧使得人目标检测与外观嵌入较不稳定，目标级 token 的信噪比较低。  
2) **异常类别包含强场景/摄像机模式差异**：某些异常类别可能伴随明显的场景变化、运动模糊、亮度变化或背景结构差异，全帧特征更易捕获。  
3) **当前 token 设计对“上下文”建模不足**：目标中心表示在抑制背景的同时也丢失了部分全局上下文（例如拥挤程度、环境状态），导致对部分异常弱化。

### tracking 的作用（B3 vs 主模型）

主模型（tracking）优于 B3（无 tracking），说明轨迹级一致性对跨片段建模有帮助。无 tracking 时，段内 top-K 检测框的身份不一致，Transformer 需要同时解决“目标对齐”和“行为建模”，难度更高。

### Transformer vs RNN（B2 vs 主模型）

在本次默认超参下，B2_yolo_gru 高于主模型，可能原因：

- GRU 在小规模数据与噪声 token 条件下更易优化（结构更简单、归纳偏置更强）
- Transformer 的层数/头数/正则参数仍需进一步调参（例如减少层数、调 dropout、调 margin 与正则权重）

## 3) 消融实验解读（A1–A6）

### A1_motion_only 显著失败（AUC=0.5518）

运动统计在“低 fps + 低分辨率 + 目标关联误差”条件下信息量不足；此外运动特征计算依赖检测框序列，若检测抖动/误检较多，会放大噪声。

### A2_appearance_only 接近主模型（AUC=0.7954）

外观嵌入仍是较强信号，但与主模型差距表明几何/运动与结构建模仍能提供增益（尽管增益有限）。

### A3 (K) 与信息量—噪声权衡

- K=5 较低（AUC=0.7685）：信息不足，容易漏掉关键目标或交互对象。  
- K=20 略高（AUC=0.8027）：信息更多，但也引入更多噪声目标；说明 K 的选择存在折中。

### A4 (depth) 体现“容量与稳健性”关系

深度=2（AUC=0.8382）优于默认深度=4（主模型平均 0.8205），而深度=6 明显退化（AUC=0.7495），提示：

- 更浅的 Transformer 更适合当前 token 噪声与数据规模  
- 过深网络可能出现过拟合或优化困难

### A5 原型库的作用（off：AUC=0.7823）

关闭 Prototype Bank 后性能下降，说明原型模式的附加表示（pattern residual）在弱监督条件下可能起到“结构化归纳偏置”的作用，并且为后续可解释分析提供接口。

### A6 FPS=5（AUC=0.8035）低于 FPS=10

更高采样率通常提供更细粒度的行为线索；但考虑到本数据的估算来源 fps 本身较低（约 3），该结论还需结合真实视频帧率与采样策略进一步验证。

## 4) 可解释性与定性分析（基于 main_targetformer seed_0）

已生成 5 个测试样例的可视化视频与时间线：

- 视频：`outputs/qualitative/main_targetformer_seed_0_*.mp4`
- 时间线：`outputs/qualitative_data/main_targetformer_seed_0_*_timeline.csv`

这些产物支持在论文中展示：

- 片段级异常分数随时间的峰值位置
- 段内 Top-K 目标框与（近似）track id
- token 权重热力图（`outputs/figures/main_targetformer_seed_0_token_heatmap.png`）用于分析模型关注的目标分布

## 5) 资源消耗与工程限制

- GPU：RTX 4060 Laptop 8GB；训练默认 AMP + 梯度累积，避免显存溢出  
- 数据形态：本地为已解帧版本，分辨率 64×64 且 frame_idx 间隔导致有效 fps 很低；对检测/外观/运动特征均有不利影响  
- 追踪器：为保证 Windows 环境稳定性，采用确定性的 IoU 关联追踪替代依赖较多的外部追踪器（该选择提升了复现稳定性，但可能牺牲追踪精度）

## 6) 后续改进方向（面向论文 Discussion）

1) 引入更强的检测器与更稳健的追踪（例如在可控环境下使用 ByteTrack/BoT-SORT），并系统评估追踪误差对 token 的影响。  
2) 将“全局上下文”与“目标中心 token”融合（例如追加全帧 token 或场景 token），缓解 B1 现象。  
3) 以更浅的 Transformer 或改进的序列建模（如轻量注意力/门控机制）提升稳健性。  
4) 若补齐 temporal annotation，可报告更标准的 frame-level AUC，并对定位质量进行更严谨评估。
